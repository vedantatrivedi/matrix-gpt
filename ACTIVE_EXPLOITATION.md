# Active Exploitation System

## Overview

The Red Team now **actively exploits** vulnerabilities instead of just reporting them. This creates real attack traffic that Blue Team can detect in logs.

## Key Features

### 1. **Exploitation Tool**
Red Team LLM can call `exploit_vulnerability()` to:
- Execute attacks multiple times (3-5 attempts recommended)
- Generate real HTTP requests with attack payloads
- Create noise in application logs
- Track success/failure rates

### 2. **Attack Suggestions Tool**
Red Team LLM can call `suggest_next_attacks()` to:
- Identify follow-up attack vectors
- Suggest privilege escalation paths
- Recommend lateral movement opportunities
- Plan data exfiltration strategies

### 3. **Updated LLM Instructions**
Red Team now operates in 3 phases:
1. **Analysis**: Parse and structure vulnerability findings
2. **Exploitation**: Actively exploit each vulnerability 3-5 times
3. **Suggestion**: Identify next attack vectors

## Implementation Files

### Core Files Modified
- `orchestrator/agents/recon.py` - Added exploitation tools
- `orchestrator/agents/red_team.py` - Updated instructions
- `orchestrator/frontend/index.html` - UI enhancements for vulnerability display

### New Functions in recon.py

#### exploit_vulnerability
```python
@function_tool
def exploit_vulnerability(url: str, vuln_type: str, attempts: int = 3) -> Dict[str, Any]:
    """
    Actively exploit a vulnerability multiple times.
    Creates detectable patterns in logs.

    Args:
        url: Target endpoint URL
        vuln_type: sqli, xss, cmdi, path_traversal, auth_bypass
        attempts: Number of exploitation attempts (3-5 recommended)

    Returns:
        {
            "url": str,
            "vuln_type": str,
            "attempts": int,
            "successful": int,
            "failed": int,
            "success_rate": str,
            "logs": List[str]
        }
    """
```

#### suggest_next_attacks
```python
@function_tool
def suggest_next_attacks(confirmed_vulns: List[Dict[str, str]]) -> Dict[str, Any]:
    """
    Suggest follow-up attacks based on confirmed vulnerabilities.

    Args:
        confirmed_vulns: List of {type, url, severity}

    Returns:
        {
            "immediate_follow_ups": [...],
            "privilege_escalation": [...],
            "lateral_movement": [...],
            "data_exfiltration": [...]
        }
    """
```

## How It Works

### Before (Passive Scanning)
```
Red Team: "Found SQL injection at /api/products"
Blue Team: *No detectable activity in logs*
```

### After (Active Exploitation)
```
Red Team: Calls exploit_vulnerability("/api/products", "sqli", attempts=5)

Logs show:
2026-02-01 15:05:10 GET /api/products?q=' OR '1'='1 → 500 Error
2026-02-01 15:05:11 GET /api/products?q=' OR 1=1-- → 500 Error
2026-02-01 15:05:12 GET /api/products?id=' UNION SELECT NULL-- → 500 Error
2026-02-01 15:05:13 GET /api/products?q=admin'-- → 500 Error
2026-02-01 15:05:14 GET /api/products?q='; DROP TABLE users-- → 500 Error

Blue Team: Can now detect repeated attack patterns!
```

## Example LLM Workflow

```
1. Pre-scan finds: SQL Injection at /api/products

2. LLM Analysis:
   "SQL Injection confirmed. Will exploit to create detectable traffic."

3. LLM calls:
   exploit_vulnerability(
       url="http://localhost:8001/api/products",
       vuln_type="sqli",
       attempts=5
   )

4. Tool executes 5 SQLi attempts with different payloads

5. LLM calls:
   suggest_next_attacks([
       {"type": "SQL Injection", "url": "/api/products", "severity": "CRITICAL"}
   ])

6. Tool returns suggestions:
   - UNION-based data extraction
   - Test admin endpoints for same vulnerability
   - Extract database schema

7. LLM outputs structured report with exploited vulnerabilities and next steps
```

## Benefits

### For Red Team
- More realistic attack simulation
- Measurable impact (success rates)
- Better coverage through suggested follow-ups

### For Blue Team
- Visible attack patterns in logs
- Real detection scenarios
- Practice identifying repeated exploit attempts

### For System
- Realistic attacker behavior simulation
- Better training data for detection systems
- Measurable defense capabilities

## Configuration

The system uses the following model (configurable via environment variable):
```python
MODEL = os.environ.get("RED_TEAM_MODEL", "gpt-4o-mini")
```

Tools are registered with the Red Team agent:
```python
red_team_commander = Agent(
    name="Red Team Commander",
    model=MODEL,
    instructions=COMMANDER_INSTRUCTIONS_FLAT,
    tools=[
        deep_dive_endpoint,
        exploit_vulnerability,
        suggest_next_attacks,
    ],
)
```

## Testing

To verify the system is working:

1. Start a battle: `curl -X POST http://localhost:8000/api/battle/start`
2. Monitor logs: `tail -f logs/agents.log`
3. Look for:
   - `[EXPLOIT] Exploiting sqli at...`
   - `✓ Attempt N: Exploited with...`
   - `Complete: N/M successful`
4. Check Blue Team can see patterns: `curl http://localhost:8000/api/logs`

## Future Enhancements

- Adaptive payloads based on responses
- Stealth mode (spaced-out requests)
- Exploit chains (combine multiple vulnerabilities)
- Persistence mechanisms
- Custom payload generation per tech stack
